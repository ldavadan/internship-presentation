---
title: "Vers une interpolation de la température avec la Régression Linéaire Multiple"
author: "loic.davadan@agro-bordeaux.fr"
date: "`r format(Sys.time(), '%d %B, %Y')`"
always_allow_html: yes
output:
  revealjs::revealjs_presentation:
    css:
      - "~/Documents/code/internship-presentation/theme/style_craw.css"
    center: no
    highlight: zenburn
    incremental: yes
    self_contained: true
    slide_level: 2
    theme: default
    transition: slide
    fig_caption: false
    reveal_options:
      previewLinks: false
  md_document:
    toc: no
    toc_depth: 6
    variant: markdown_github
  word_document:
    toc: no
    toc_depth: '6'
  odt_document:
    fig_height: 5
    fig_width: 7
  pdf_document: default
  html_document:
    theme: default
    toc: yes
    toc_depth: 6
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---

```{r include=FALSE}
load("~/Documents/code/internship-presentation/data/env_data_presentation.RData")
```

# 1. Objectifs
##
* Spatialiser des données de températures prédites à l'aide de la Régression Linéaire Multiple en vue d'une comparaison avec d'autres méthodes statistiques (krigeage, réseaux neuronaux...) pour évaluer la meilleure méthode.

* Intégrer des variables explicatives et trouver la meilleure combinaison de ces variables fournissant des prédictions avec une RMSE faible.

# 2. Travaux réalisés
##
Préparation de l'environnement de travail

* Installation de Linux : Open-source, science reproductible

* Utilisation de Docker : Environnement de travail isolé avec configuration différente de l'ordinateur hôte. Assure la reproductibilité du code

* Utilisation de GitHub : Service de gestion de versions -> Travail collaboratif

## 2.1 Récolte des données   

_Objectif_ : intégrer des variables explicatives pouvant influencer des paramètres du milieu

Nécessité d'avoir des données sur les variables d'intérêt pour pouvoir les prédire

### 2.1.1. Variables explicatives

#### 2.1.1.1 Variables statiques

Données d'occupation du sol : 

* Stations en zones agricoles mais environnement à caractériser (route en asphalte à proximité ? forêt faisant de l'ombre ?)

* CORINE Land Cover : données de [Copernicus](https://land.copernicus.eu/pan-european/corine-land-cover/view) accessibles sur le [géoportail belge](https://www.geo.be/#!/catalog/details/bcd19aa9-c320-4116-971b-6e4376137f13?l=en)

----

* 47 classes dont 26 présentes en Wallonie -> regroupement en 5 classes : Zones artificielles, Zones de cultures, Zones herbacées, Forêt et Plans d'eau

* Récupération des données aux stations : zones tampons (100m autour des stations physiques et 500m pour les stations virtuelles) et calcul de la part de chaque classe dans l'environnement de la station

```{r echo=FALSE}
head(class.buff.clean.df)
```

----

![](./data/CLC_buffer.png){width=100%}

----

Modèle Numérique de Terrain

* Caractériser l'effet de la topographie du milieu sur la température

* Données [SRTM](https://lta.cr.usgs.gov/SRTM) pour récupérer l'altitude (résolution 90m) puis calcul de la pente, l'orientation et la rugosité du terrain avec R

* Données très volumineuses = Temps de calcul important

### 2.1.1.2. Variables dynamiques

API ensoleillement

* Caractériser l'impact du rayonnement solaire (W/m²) sur la température

* Rayonnement solaire : données [EUMETSAT](https://landsaf.ipma.pt/en/products/longwave-shortwave-radiation/dssf/) récupérées sur une API

----

* Données horaires, 875 points répartis sur la Wallonie -> insuffisant pour la précision souhaitée d'1 km² (~ 17000 points)

* Spatialisation des données solaires à l'aide d'une méthode de krigeage

* Récupération des données d'ensoleillement des stations PAMESEB en parallèle

## 2.1.2. Variables d'intérêt

API AGROMET

* Besoin de données pour construire les modèles et les comparer à la réalité

* 29 stations du réseau PAMESEB

* Accès à des données dynamiques horaires : __température__, humidité relative, humectation du feuillage

* 27 stations utilisables si on prend l'ensoleillement

## 2.2. Organisation des données

_Objectif_ : construire des modèles pour chaque heure

Regroupement des données statiques et dynamiques de chaque station.

Pour optimiser le temps de calcul et l'intégration dans `mlr`, création d'un "nested data frame" : chaque heure contient un ou plusieurs tableaux de données

![](./data/purrr_nest.png){width=30%}

## 2.3. Modélisation

### 2.3.1. Machine learning

_Définition_ : Le Machine Learning est un concept stipulant qu’il existe des algorithmes génériques pouvant nous révéler des informations intéressantes sur des données, sans avoir besoin de construire ou de développer un code spécifique. Au lieu d’écrire du code, vous nourrissez donc ces algorithmes avec des données qui leur permettront de construire leurs propres logiques.

_Objectif_ : Réaliser un benchmark appliquant la Régression Linéaire Multiple à différentes combinaisons de variables explicatives et au paramètre ciblé en utilisant une stratégie de rééchantillonage par validation croisée (LOOCV).

----

### 2.3.2. Machine Learning in R

`mlr` : package R proposant une interface simplifiée et commune pour toutes les méthodes statistiques à intégrer dans le machine learning.

Paramètres à définir pour la modélisation :

* Le paramètre ciblé : Température

* Les méthodes statistiques d'apprentissage : Régression linéaire multiple

* Les variables explicatives à comparer : MNT, occupation du sol, ensoleillement

* La méthode de rééchantillonage : validation croisée par Leave-One-Out


# 3. Résultats

## 3.1. Visualisation du modèle 

* Graphiques des résultats du benchmark

* Equation de régression du modèle et ses coefficients

* Cartes : Statiques ou interactives (leaflet) & Visualisation des prédictions pour une heure donnée mais aussi de l'erreur relative

* Création d'une couche contenant les prédictions, visualisée avec une palette de couleur

* Création d'une couche contenant l'erreur associée à chaque prédiction avec un niveau de transparence variable (couche blanche avec opacité plus importante si l'erreur est élevée)

## 3.2. Premiers résultats

Modèle sur 2 mois

![](./data/template_map.png){width=60%}




# 4. Perspectives et conclusions
##
La démarche est définie et prête pour créer les modèles.

_Prochains objectifs_ :

* Créer les modèles à partir de 5 ans de données

* Identifier la meilleure combinaison de variables explicatives

* Appliquer cette combinaison à la grille d'interpolation

* Créer une _Shiny app_ pour la visualisation des données



